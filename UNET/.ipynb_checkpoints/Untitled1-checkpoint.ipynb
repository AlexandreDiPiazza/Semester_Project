{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82cfd981",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08686936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.5, 2. ])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1,1],[2,3]])\n",
    "np.mean(a, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c55cafc0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-a706e49e413d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import os\n",
    "import gc\n",
    "import random \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\n",
    "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D\n",
    "from keras.layers.merge import concatenate, add\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense\n",
    "\n",
    "np.random.seed(1234)\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "def conv2d_block(input_tensor, n_filters, kernel_size = 3, batchnorm = True):\n",
    "    \"\"\"Function to add 2 convolutional layers with the parameters passed to it\"\"\"\n",
    "    # first layer\n",
    "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
    "              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \"\"\"\"\n",
    "    # second layer\n",
    "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
    "              kernel_initializer = 'he_normal', padding = 'same')(x)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\"\"\"\n",
    "    \n",
    "    return x\n",
    "\n",
    "def get_unet(input_img, n_filters = 32, dropout = 0.1, batchnorm = True):\n",
    "    \"\"\"Function to define the UNET Model\"\"\"\n",
    "    # Contracting Path\n",
    "    c1 = conv2d_block(input_img, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "    p1 = Dropout(dropout)(p1)\n",
    "    \n",
    "    c2 = conv2d_block(p1, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "    p2 = Dropout(dropout)(p2)\n",
    "    \n",
    "    c3 = conv2d_block(p2, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "    p3 = Dropout(dropout)(p3)\n",
    "    \n",
    "    c4 = conv2d_block(p3, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p4 = MaxPooling2D((2, 2))(c4)\n",
    "    p4 = Dropout(dropout)(p4)\n",
    "    \n",
    "    c5 = conv2d_block(p4, n_filters = n_filters * 16, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    # Expansive Path\n",
    "    u6 = Conv2DTranspose(n_filters * 8, (3, 3), strides = (2, 2), padding = 'same')(c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    u6 = Dropout(dropout)(u6)\n",
    "    c6 = conv2d_block(u6, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    u7 = Conv2DTranspose(n_filters * 4, (3, 3), strides = (2, 2), padding = 'same')(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    u7 = Dropout(dropout)(u7)\n",
    "    c7 = conv2d_block(u7, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    u8 = Conv2DTranspose(n_filters * 2, (3, 3), strides = (2, 2), padding = 'same')(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    u8 = Dropout(dropout)(u8)\n",
    "    c8 = conv2d_block(u8, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    u9 = Conv2DTranspose(n_filters * 1, (3, 3), strides = (2, 2), padding = 'same')(c8)\n",
    "    u9 = concatenate([u9, c1])\n",
    "    u9 = Dropout(dropout)(u9)\n",
    "    c9 = conv2d_block(u9, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    "    model = Model(inputs=[input_img], outputs=[outputs])\n",
    "    return model\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=5, verbose=1),\n",
    "    ReduceLROnPlateau(factor=0.1, patience=2, min_lr=1e-5, verbose=1),\n",
    "]\n",
    "\n",
    "\n",
    "def jaccard_distance(y_true, y_pred):\n",
    "    \"\"\" Calculates mean of Jaccard distance as a loss function \"\"\"\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=(1,2))\n",
    "    sum_ = tf.reduce_sum(y_true + y_pred, axis=(1,2))\n",
    "    jac = (intersection + 100.) / (sum_ - intersection + 100.)\n",
    "    jd =  (1 - jac) * 100.\n",
    "    return tf.reduce_mean(jd)\n",
    "\n",
    "X_vraie = np.load('X_vraie_augmented.npy')\n",
    "Y_vraie = np.load('Y_vraie_augmented.npy')\n",
    "\n",
    "import random\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import albumentations as A\n",
    "    \n",
    "transform = A.Compose(\n",
    "    [\n",
    "    A.VerticalFlip(p=0.8),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.ShiftScaleRotate(p=0.6),\n",
    "    ],\n",
    "    additional_targets={'image0': 'image'}\n",
    ")\n",
    "\n",
    "for i in range(32) : \n",
    "    transformed = transform(image=X_vraie[i,:,:], image0=Y_vraie[i,:,:])\n",
    "    im1 = np.reshape(transformed['image'], newshape = (1,256,256)); \n",
    "    im2 = np.reshape(transformed['image0'], newshape = (1, 256, 256)); \n",
    "    #X_vraie = np.vstack((X_vraie, im1))\n",
    "    X_vraie = np.append(X_vraie, im1, axis = 0)\n",
    "    Y_vraie = np.append(Y_vraie, im2, axis = 0)\n",
    "\n",
    "def load_model(learning_rate, dropout,i):\n",
    "    im_height = 256\n",
    "    im_width = 256\n",
    "    input_img = Input((im_height, im_width, 1), name='img')\n",
    "    model = get_unet(input_img, n_filters= 32, dropout=dropout, batchnorm=True)\n",
    "    model.compile(optimizer=Adam(lr =learning_rate), loss=\"binary_crossentropy\", metrics=[jaccard_distance])\n",
    "    model.load_weights('model1')\n",
    "    \n",
    "    # depend on the values of i, block some layers\n",
    "    index = 0\n",
    "    for layer in model.layers : \n",
    "        index += 1\n",
    "        #print(index,layer.name)\n",
    "        if i == 1 : \n",
    "            if index == 46 or index == 49 : \n",
    "                layer.trainable = True\n",
    "            else : \n",
    "                layer.trainable = False\n",
    "        elif i == 2 : \n",
    "            if index == 49 : \n",
    "            #if index == 46 or index == 49 or index == 40:  \n",
    "                layer.trainable = True\n",
    "            else : \n",
    "                layer.trainable = False\n",
    "            \n",
    "    return model \n",
    "\n",
    "def build_k_indices(y, k_fold, seed):\n",
    "    \"\"\"build k indices for k-fold.\"\"\"\n",
    "    num_row = np.shape(y)[0]\n",
    "    interval = int(num_row / k_fold)\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.permutation(num_row)\n",
    "    k_indices = [indices[k * interval: (k + 1) * interval] for k in range(k_fold)]\n",
    "    return np.array(k_indices)\n",
    "def Dice_index(pred, true) :\n",
    "    TP = 0; TN = 0 ;\n",
    "    FP = 0; FN = 0; \n",
    "    for i in range(256) : \n",
    "        for j in range(256) : \n",
    "            if pred[i,j] == 1 : \n",
    "                if true[i,j] == 1 : \n",
    "                    TP +=1 \n",
    "                else : \n",
    "                    FP +=1\n",
    "            else : \n",
    "                if true[i,j] == 0:\n",
    "                    TN +=1\n",
    "                else : \n",
    "                    FP +=1\n",
    "    \n",
    "    Dice = 2 * TP / (2*TP + FP + FN) if TP != 0 else 0 \n",
    "    \n",
    "    accuracy = (TP + TN) / (TP + FP + TN + FN)\n",
    "    recall=TP/(TP+FN) if TP + FN != 0 else 0\n",
    "    specificity = TN/(TN+FP) if TN + FP != 0 else 0 \n",
    "    precision = TP / (TP + FP) if TP + FP != 0 else 0 \n",
    "    NPV = TN / (TN + FN) if TN + FN != 0 else 0 \n",
    "    \n",
    "    \n",
    "    return Dice, accuracy, recall, specificity, precision, NPV \n",
    "\n",
    "def results(model, x_test, y_test, tresh) :\n",
    "    Dic = []; Acc = [] ; Rec = [] ; Spe = [] ; Pre = [] ; NPVs = [] ;\n",
    "    for i in range(np.shape(x_test)[0]) : \n",
    "        prediction = model.predict(x_test[i,:,:].reshape(1,256,256,1)).reshape((256,256))\n",
    "        prediction[prediction>0.25] = 1\n",
    "        prediction[prediction<0.25] = 1\n",
    "        Dice, accuracy, recall, specificity, precision, NPV = Dice_index(prediction, y_test[i,:,:])\n",
    "        Dic.append(Dice);Acc.append(accuracy);Rec.append(recall);Pre.append(precision);Spe.append(specificity)\n",
    "        NPVs.append(NPV)\n",
    "    return sum(Dic)/len(Dic), sum(Acc)/len(Acc), sum(Rec)/len(Rec), sum(Spe)/len(Spe), sum(Pre)/len(Pre), sum(NPVs)/len(NPVs)\n",
    "                                                                               \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5432fd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [1e-2, 5*1e-3, 1e-4]\n",
    "learning_rates = [1e-2, 1e-4]\n",
    "learning_rates = [1e-2]\n",
    "\n",
    "dropouts = [0.1, 0.2]\n",
    "dropouts = [0.1]\n",
    "\n",
    "Epochs = [10, 15, 20]\n",
    "Epochs = [20]\n",
    "\n",
    "tresholds = [0.15, 0.25, 0.3]\n",
    "tresholds = [0.15] \n",
    "\n",
    "k_fold = 5\n",
    "k_fold = 2\n",
    "seed = 1\n",
    "k_indices = build_k_indices(X_vraie, k_fold, 1) \n",
    "\n",
    "all_results =np.array([1,1,1,1,1,1,1,1,1,1,1])\n",
    "for i in range(3) :\n",
    "    for lr in learning_rates : \n",
    "        for dro in dropouts : \n",
    "            for ep in Epochs : \n",
    "                for tr in tresholds : \n",
    "                    Ds = [] ; As = [] ; Rs = [] ; Ss = [];\n",
    "                    Ps = [] ; Ns = [];\n",
    "                    for k in range(k_fold) : \n",
    "                        if k == 1 : \n",
    "                            break \n",
    "                        if 'model' in locals() : \n",
    "                            del model \n",
    "                        model = load_model(lr, dro, i)\n",
    "                        #model.trainable = True\n",
    "                        te_indice = k_indices[k]\n",
    "                        tr_indice = k_indices[~(np.arange(k_indices.shape[0]) == k)]\n",
    "                        tr_indice = tr_indice.reshape(-1)\n",
    "                        y_te = Y_vraie[te_indice]\n",
    "                        y_tr = Y_vraie[tr_indice]\n",
    "                        x_te = X_vraie[te_indice]\n",
    "                        x_tr = X_vraie[tr_indice]\n",
    "                        print('start')\n",
    "                        print(i)\n",
    "                        print(len(model.trainable_weights))\n",
    "                        test = np.mean(model.predict(X_vraie[0,:,:].reshape(1,256,256,1)).reshape((256,256)))\n",
    "                        print(test)\n",
    "                        model.fit(x_tr, y_tr, batch_size=10, epochs=ep)\n",
    "                              \n",
    "                        test = np.mean(model.predict(X_vraie[0,:,:].reshape(1,256,256,1)).reshape((256,256)))\n",
    "                        print(test)\n",
    "                        print(len(model.trainable_weights))\n",
    "                        print('ok')\n",
    "                        params = len(model.trainable_weights)\n",
    "                        model.trainable = False\n",
    "                        D, A, R, S, P, N = results(model, x_te, y_te, tr) \n",
    "                        Ds.append(D); As.append(A);Rs.append(R);Ss.append(S);\n",
    "                        Ps.append(P); Ns.append(N);\n",
    "                    D_m = sum(Ds)/len(Ds) ; A_m = sum(As)/len(As) ; R_m = sum(Rs)/len(Rs)\n",
    "                    S_m = sum(Ss)/len(Ss) ; P_m = sum(Ps)/len(Ps) ; N_m = sum(Ns)/len(Ns)\n",
    "                    print(params)\n",
    "                    values = [i, lr, dro, tr, D_m, A_m, R_m, S_m, P_m, N_m, params]\n",
    "                    all_results = np.vstack((all_results, values))\n",
    "np.save('fine_tuning.npy', all_results)                \n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".test",
   "language": "python",
   "name": ".test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
